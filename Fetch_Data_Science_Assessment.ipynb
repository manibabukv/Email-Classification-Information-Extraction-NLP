{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Collection"
      ],
      "metadata": {
        "id": "cPyy_f10EKTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB-KiRNFEDhu"
      },
      "outputs": [],
      "source": [
        "import pandas as ps\n",
        "\n",
        "df = read_csv('file_path') #assuming file is of type csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data Exploration"
      ],
      "metadata": {
        "id": "j19MrJUaEQdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df.groupby('category').emails_data.count().plot.bar(ylim = 0)\n",
        "plt.show() #displays histogram with class distributions\n",
        "\n",
        "df['category'].value_counts() #gives count of each category\n",
        "\n",
        "df = df[pd.notnull(df['emails_data'])] #removes missing values from the emails_data column\n",
        "\n",
        "df = df[pd.notnull(df['category'])] #removes missing values from the category column"
      ],
      "metadata": {
        "id": "EfhekjKwEVZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Data Cleaning"
      ],
      "metadata": {
        "id": "_LWKd5uGEYX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from html import unescape\n",
        "\n",
        "# function that creates new column with email data without urls\n",
        "\n",
        "def remove_url(df):\n",
        "    df['clean_email_data'] = ''\n",
        "    for i in range(len(df)):\n",
        "        uncleaned_text = df['emails_data'][i]\n",
        "        clean_email_data = unescape(clean_email_data)\n",
        "        final_data = BeautifulSoup(clean_email_data)\n",
        "        clean_email= final_data.get_text()\n",
        "        df['clean_email_data'][i]= clean_email\n",
        "    return df"
      ],
      "metadata": {
        "id": "oOsIPq8GEa1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Text Processing"
      ],
      "metadata": {
        "id": "7DuMFDnhEelU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('stopwords')\n",
        "\n",
        "df['lower_case'] = df['emails_data'].apply(lambda x: x.lower().strip().replace('\\n', ' ').replace('\\r', ' '))\n",
        "\n",
        "df['without-link'] = df['lower_case'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "df['Special_word'] = df.apply(lambda row: tokenizer.tokenize(row['lower_case']), axis=1)\n",
        "\n",
        "stop = [word for word in stopwords.words('english')]\n",
        "\n",
        "df['stop_words'] = df['Special_word'].apply(lambda x: [item for item in x if item not in stop])\n",
        "\n",
        "df['stop_words'] = df['stop_words'].astype('str')\n",
        "\n",
        "df['short_word'] = df['stop_words'].str.findall('\\w{2,}')\n",
        "\n",
        "df['string']=df['short_word'].str.join(' ')\n",
        "\n",
        "df['Text'] = df['string'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "# Vectorization and Coverting categorical labels to numeric labels\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[\"emails_data\"],df[\"category\"], test_size = 0.25, random_state = 42)\n",
        "\n",
        "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
        "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
        "\n",
        "x_train_counts = count_vect.fit_transform(x_train)\n",
        "x_train_tfidf = transformer.fit_transform(x_train_counts)\n",
        "\n",
        "x_test_counts = count_vect.transform(x_test)\n",
        "x_test_tfidf = transformer.transform(x_test_counts)"
      ],
      "metadata": {
        "id": "Tqtw8PxEEiCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Random Forest Implementation"
      ],
      "metadata": {
        "id": "_taf07jzEyzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=300, max_depth=15, random_state=42, class_weight='balanced')\n",
        "rfc.fit(x_train_tfidf,y_train)"
      ],
      "metadata": {
        "id": "PeIzWyoiE81Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Evaluation"
      ],
      "metadata": {
        "id": "Q95CTX68FFe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, f1_score, recall_score\n",
        "\n",
        "y_pred = rfc.predict(x_test_tfidf)\n",
        "print(\"Accuracy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "AXrVJS0-FK2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Code for Extracting price from text"
      ],
      "metadata": {
        "id": "oZNQfhsQFOuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_total_amount(text):\n",
        "    #Define regular expressions for common currency patterns\n",
        "    currency_patterns = [\n",
        "        r'\\$\\s?(\\d+(\\.\\d{1,2})?)',  # $ followed by digits and optional decimal\n",
        "        r'(\\d+(\\.\\d{1,2})?)\\s?USD',  # Digits followed by USD\n",
        "        r'(\\d+(\\.\\d{1,2})?)\\s?EUR',  # Digits followed by EUR\n",
        "    ]\n",
        "\n",
        "    total_amount = None\n",
        "    for pattern in currency_patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            total_amount = float(match.group(1))\n",
        "            break\n",
        "\n",
        "    return total_amount\n",
        "\n",
        "#Test the function with sample text\n",
        "sample_text = \"Your total payment is $150.45. Thank you!\"\n",
        "total_amount = extract_total_amount(sample_text)\n",
        "if total_amount:\n",
        "    print(f\"Extracted Total Amount: ${total_amount:.2f}\")\n",
        "else:\n",
        "    print(\"Total amount not found in the text.\")"
      ],
      "metadata": {
        "id": "CaDVsxctFWT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}